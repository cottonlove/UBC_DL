{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# import Library"
      ],
      "metadata": {
        "id": "r361BnZQS7mw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HMRQJPctS0wt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from PIL import Image\n",
        "from collections import OrderedDict #for multiGPU\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU"
      ],
      "metadata": {
        "id": "cYz4uwczS_TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
        "#for colab\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"device is \", device)"
      ],
      "metadata": {
        "id": "kGUwO9AzTAsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d9a547-2fea-434a-8c0c-526eeaa25096"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device is  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "3vnC5jddTCQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"loading dataset\")\n",
        "\n",
        "data_transforms = {\n",
        "    'train' : transforms.Compose([ #horizontal flip, random crop, normalization           \n",
        "            #transforms.ToPILImage(),\n",
        "            # transforms.Resize((256,256)),\n",
        "            transforms.RandomCrop(32, padding = 4), #augmentation, input for ResNet\n",
        "            transforms.RandomHorizontalFlip(), #augmentation\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "            #transforms.Normalize((0.4914, 0.4822, 0.4465), (1, 1, 1)), #with the per-pixel mean subtracted\n",
        "\n",
        "        ]) , \n",
        "        'test': transforms.Compose([\n",
        "            transforms.ToTensor(), #single view of the original 32x32 image\n",
        "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "        ])\n",
        "    }\n",
        "#access data_transforms['train']\n",
        "\n",
        "#dataloader (batch)\n",
        "train_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform = data_transforms['train']\n",
        ")\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size = 128, shuffle = True, num_workers=2\n",
        ")\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=data_transforms['test'])\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "#classes\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "metadata": {
        "id": "F-92lZOoTDeE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe8fa2b-d9ad-4b14-8bc5-e8691c5d9b78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dataset\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 102857450.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "iFbGdgWQTGtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class optionA(nn.Module):\n",
        "  def __init__(self, func):\n",
        "    super(optionA, self).__init__()\n",
        "    self.func = func\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.func(x)"
      ],
      "metadata": {
        "id": "nhHtqcMM13Zp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fx2_16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(16, 16, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(16)\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(16, 16, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(16)\n",
        "    )\n",
        "    self.residual = nn.Sequential()\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.conv1(x))\n",
        "    out = self.conv2(out)\n",
        "    out +=self.residual(x)\n",
        "    out = F.relu(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "CeLXC5vcDZy6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fx2_32(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(32, 32, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(32)\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 32, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(32),\n",
        "    )\n",
        "    self.residual = nn.Sequential()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.conv1(x))\n",
        "    out = self.conv2(out)\n",
        "    out += self.residual(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "lbfuoAhFFTYI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Fx2_64(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "         nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(64)\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(64)\n",
        "    )\n",
        "    self.residual = nn.Sequential()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.conv1(x))\n",
        "    out = self.conv2(out)\n",
        "    out += self.residual(x)\n",
        "    out = F.relu(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "1DOtnYb7FQsq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classes for Resnet56 Model\n",
        "class conv16 (nn.Module): #Blue\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Fx1 = Fx2_16()\n",
        "    self.Fx2 = Fx2_16()\n",
        "    self.Fx3 = Fx2_16()\n",
        "    self.Fx4 = Fx2_16()\n",
        "    self.Fx5 = Fx2_16()\n",
        "    self.Fx6 = Fx2_16()\n",
        "    self.Fx7 = Fx2_16()\n",
        "    self.Fx8 = Fx2_16()\n",
        "    self.Fx9 = Fx2_16()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    x1 = self.Fx1(x)\n",
        "    x2 = self.Fx2(x1)\n",
        "    x3 = self.Fx3(x2) \n",
        "    x4 = self.Fx4(x3) \n",
        "    x5 = self.Fx5(x4) \n",
        "    x6 = self.Fx6(x5) \n",
        "    x7 = self.Fx7(x6) \n",
        "    x8 = self.Fx8(x7) \n",
        "    x9 = self.Fx9(x8)\n",
        "    #x = self.relu(x)\n",
        "    return x9\n",
        "\n",
        "#classes for Resnet56 Model\n",
        "class conv32 (nn.Module): #Purple\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Fx1_1 = nn.Sequential(\n",
        "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
        "        nn.Conv2d(16, 32, kernel_size = 3, stride = 2, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(32))\n",
        "    self.Fx1_2 = nn.Sequential(\n",
        "        nn.Conv2d(32, 32, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(32)\n",
        "    )\n",
        "\n",
        "    ## OptionB\n",
        "    # self.residual_mapping = nn.Sequential(\n",
        "    #     nn.Conv2d(16,32,kernel_size =1, stride = 2, bias= False),\n",
        "    #     nn.BatchNorm2d(32)\n",
        "    # )\n",
        "\n",
        "    # ## OptionA\n",
        "    self.residual_mapping = optionA(lambda x: F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, 32//4, 32//4), \"constant\", 0))\n",
        "\n",
        "    self.Fx2 = Fx2_32()\n",
        "    self.Fx3 = Fx2_32()\n",
        "    self.Fx4 = Fx2_32()\n",
        "    self.Fx5 = Fx2_32()\n",
        "    self.Fx6 = Fx2_32()\n",
        "    self.Fx7 = Fx2_32()\n",
        "    self.Fx8 = Fx2_32()\n",
        "    self.Fx9 = Fx2_32()\n",
        "    # self.relu = nn.ReLU()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out = F.relu(self.Fx1_1(x))\n",
        "    out = self.Fx1_2(out) \n",
        "    out += self.residual_mapping(x)\n",
        "    x1 = F.relu(out)\n",
        "    \n",
        "    x2 = self.Fx2(x1) \n",
        "    x3 = self.Fx3(x2) \n",
        "    x4 = self.Fx4(x3) \n",
        "    x5 = self.Fx5(x4) \n",
        "    x6 = self.Fx6(x5) \n",
        "    x7 = self.Fx7(x6) \n",
        "    x8 = self.Fx8(x7) \n",
        "    x9 = self.Fx9(x8) \n",
        "    # x2 = self.Fx2(x1) + x1\n",
        "    # x3 = self.Fx3(x2) + x2\n",
        "    #x = self.relu(x)\n",
        "    return x9\n",
        "\n",
        "#classes for Resnet56 Model\n",
        "class conv64 (nn.Module): #Green\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.Fx1_1 = nn.Sequential(\n",
        "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
        "        nn.Conv2d(32, 64, kernel_size = 3, stride = 2, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(64)\n",
        "    )\n",
        "    self.Fx1_2 = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(64)\n",
        "    )\n",
        "\n",
        "    ## OptionB\n",
        "    # self.residual_mapping = nn.Sequential(\n",
        "    #     nn.Conv2d(32,64,kernel_size =1, stride = 2, bias= False),\n",
        "    #     nn.BatchNorm2d(64)\n",
        "    # )\n",
        "\n",
        "    ## OptionA\n",
        "    self.residual_mapping = optionA(lambda x: F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, 64//4, 64//4), \"constant\", 0))\n",
        "    \n",
        "    self.Fx2 = Fx2_64()\n",
        "    self.Fx3 = Fx2_64()\n",
        "    self.Fx4 = Fx2_64()\n",
        "    self.Fx5 = Fx2_64()\n",
        "    self.Fx6 = Fx2_64()\n",
        "    self.Fx7 = Fx2_64()\n",
        "    self.Fx8 = Fx2_64()\n",
        "    self.Fx9 = Fx2_64()\n",
        "\n",
        "    # self.relu = nn.ReLU()\n",
        "    \n",
        "  def forward(self,x):\n",
        "    out = F.relu(self.Fx1_1(x))\n",
        "    out = self.Fx1_2(out)\n",
        "    out += self.residual_mapping(x)\n",
        "    x1 = F.relu(out)\n",
        "    x2 = self.Fx2(x1) \n",
        "    x3 = self.Fx3(x2) \n",
        "    x4 = self.Fx4(x3) \n",
        "    x5 = self.Fx5(x4)\n",
        "    x6 = self.Fx6(x5) \n",
        "    x7 = self.Fx7(x6) \n",
        "    x8 = self.Fx8(x7) \n",
        "    x9 = self.Fx9(x8) \n",
        "\n",
        "    return x9\n",
        "   \n"
      ],
      "metadata": {
        "id": "o03lC-zU_phA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module): #Resnet56 architecture implementation\n",
        "    def __init__(self, conv2 = conv16, conv3 = conv32,\n",
        "            conv4 = conv64, num_classes = 10, init_weights = True): #num_classes\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding=1, bias = False),\n",
        "            nn.BatchNorm2d(16)\n",
        "        )\n",
        "        self.conv2 = conv2()\n",
        "        self.conv3 = conv3()\n",
        "        self.conv4 = conv4()\n",
        "        #self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fclayer = nn.Linear(64, num_classes)\n",
        "\n",
        "        if init_weights:\n",
        "            self.initialize_weights()\n",
        "    \n",
        "    # define weight initialization function\n",
        "    def initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0) \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = F.relu(self.conv1(x))\n",
        "        x2 = self.conv2(x1)\n",
        "        x3 = self.conv3(x2)\n",
        "        x4 = self.conv4(x3)\n",
        "        x = F.avg_pool2d(x4, x4.size()[3])\n",
        "        #x = self.avg_pool(x4)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output = self.fclayer(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "X_8snFMI_q5z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet56 = MyModel()"
      ],
      "metadata": {
        "id": "Q5t8Cl1VHw-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(resnet56, (3,32,32))"
      ],
      "metadata": {
        "id": "swe8ApzqTMcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07680997-35fa-4bc4-ab22-99a95d6e1afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
            "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
            "            Fx2_16-7           [-1, 16, 32, 32]               0\n",
            "            Conv2d-8           [-1, 16, 32, 32]           2,304\n",
            "       BatchNorm2d-9           [-1, 16, 32, 32]              32\n",
            "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
            "           Fx2_16-12           [-1, 16, 32, 32]               0\n",
            "           Conv2d-13           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-14           [-1, 16, 32, 32]              32\n",
            "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
            "           Fx2_16-17           [-1, 16, 32, 32]               0\n",
            "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
            "           Conv2d-20           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-21           [-1, 16, 32, 32]              32\n",
            "           Fx2_16-22           [-1, 16, 32, 32]               0\n",
            "           Conv2d-23           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-24           [-1, 16, 32, 32]              32\n",
            "           Conv2d-25           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-26           [-1, 16, 32, 32]              32\n",
            "           Fx2_16-27           [-1, 16, 32, 32]               0\n",
            "           Conv2d-28           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-29           [-1, 16, 32, 32]              32\n",
            "           Conv2d-30           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-31           [-1, 16, 32, 32]              32\n",
            "           Fx2_16-32           [-1, 16, 32, 32]               0\n",
            "           Conv2d-33           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-34           [-1, 16, 32, 32]              32\n",
            "           Conv2d-35           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-36           [-1, 16, 32, 32]              32\n",
            "           Fx2_16-37           [-1, 16, 32, 32]               0\n",
            "           Conv2d-38           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-39           [-1, 16, 32, 32]              32\n",
            "           Conv2d-40           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-41           [-1, 16, 32, 32]              32\n",
            "           Fx2_16-42           [-1, 16, 32, 32]               0\n",
            "           Conv2d-43           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-44           [-1, 16, 32, 32]              32\n",
            "           Conv2d-45           [-1, 16, 32, 32]           2,304\n",
            "      BatchNorm2d-46           [-1, 16, 32, 32]              32\n",
            "           Fx2_16-47           [-1, 16, 32, 32]               0\n",
            "           conv16-48           [-1, 16, 32, 32]               0\n",
            "           Conv2d-49           [-1, 32, 16, 16]           4,608\n",
            "      BatchNorm2d-50           [-1, 32, 16, 16]              64\n",
            "           Conv2d-51           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-52           [-1, 32, 16, 16]              64\n",
            "          optionA-53           [-1, 32, 16, 16]               0\n",
            "           Conv2d-54           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-55           [-1, 32, 16, 16]              64\n",
            "           Conv2d-56           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-57           [-1, 32, 16, 16]              64\n",
            "           Fx2_32-58           [-1, 32, 16, 16]               0\n",
            "           Conv2d-59           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-60           [-1, 32, 16, 16]              64\n",
            "           Conv2d-61           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-62           [-1, 32, 16, 16]              64\n",
            "           Fx2_32-63           [-1, 32, 16, 16]               0\n",
            "           Conv2d-64           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-65           [-1, 32, 16, 16]              64\n",
            "           Conv2d-66           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-67           [-1, 32, 16, 16]              64\n",
            "           Fx2_32-68           [-1, 32, 16, 16]               0\n",
            "           Conv2d-69           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-70           [-1, 32, 16, 16]              64\n",
            "           Conv2d-71           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-72           [-1, 32, 16, 16]              64\n",
            "           Fx2_32-73           [-1, 32, 16, 16]               0\n",
            "           Conv2d-74           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-75           [-1, 32, 16, 16]              64\n",
            "           Conv2d-76           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-77           [-1, 32, 16, 16]              64\n",
            "           Fx2_32-78           [-1, 32, 16, 16]               0\n",
            "           Conv2d-79           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-80           [-1, 32, 16, 16]              64\n",
            "           Conv2d-81           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-82           [-1, 32, 16, 16]              64\n",
            "           Fx2_32-83           [-1, 32, 16, 16]               0\n",
            "           Conv2d-84           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-85           [-1, 32, 16, 16]              64\n",
            "           Conv2d-86           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-87           [-1, 32, 16, 16]              64\n",
            "           Fx2_32-88           [-1, 32, 16, 16]               0\n",
            "           Conv2d-89           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-90           [-1, 32, 16, 16]              64\n",
            "           Conv2d-91           [-1, 32, 16, 16]           9,216\n",
            "      BatchNorm2d-92           [-1, 32, 16, 16]              64\n",
            "           Fx2_32-93           [-1, 32, 16, 16]               0\n",
            "           conv32-94           [-1, 32, 16, 16]               0\n",
            "           Conv2d-95             [-1, 64, 8, 8]          18,432\n",
            "      BatchNorm2d-96             [-1, 64, 8, 8]             128\n",
            "           Conv2d-97             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-98             [-1, 64, 8, 8]             128\n",
            "          optionA-99             [-1, 64, 8, 8]               0\n",
            "          Conv2d-100             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-101             [-1, 64, 8, 8]             128\n",
            "          Conv2d-102             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-103             [-1, 64, 8, 8]             128\n",
            "          Fx2_64-104             [-1, 64, 8, 8]               0\n",
            "          Conv2d-105             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-106             [-1, 64, 8, 8]             128\n",
            "          Conv2d-107             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-108             [-1, 64, 8, 8]             128\n",
            "          Fx2_64-109             [-1, 64, 8, 8]               0\n",
            "          Conv2d-110             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-111             [-1, 64, 8, 8]             128\n",
            "          Conv2d-112             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-113             [-1, 64, 8, 8]             128\n",
            "          Fx2_64-114             [-1, 64, 8, 8]               0\n",
            "          Conv2d-115             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-116             [-1, 64, 8, 8]             128\n",
            "          Conv2d-117             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-118             [-1, 64, 8, 8]             128\n",
            "          Fx2_64-119             [-1, 64, 8, 8]               0\n",
            "          Conv2d-120             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-121             [-1, 64, 8, 8]             128\n",
            "          Conv2d-122             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-123             [-1, 64, 8, 8]             128\n",
            "          Fx2_64-124             [-1, 64, 8, 8]               0\n",
            "          Conv2d-125             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-126             [-1, 64, 8, 8]             128\n",
            "          Conv2d-127             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-128             [-1, 64, 8, 8]             128\n",
            "          Fx2_64-129             [-1, 64, 8, 8]               0\n",
            "          Conv2d-130             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-131             [-1, 64, 8, 8]             128\n",
            "          Conv2d-132             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-133             [-1, 64, 8, 8]             128\n",
            "          Fx2_64-134             [-1, 64, 8, 8]               0\n",
            "          Conv2d-135             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-136             [-1, 64, 8, 8]             128\n",
            "          Conv2d-137             [-1, 64, 8, 8]          36,864\n",
            "     BatchNorm2d-138             [-1, 64, 8, 8]             128\n",
            "          Fx2_64-139             [-1, 64, 8, 8]               0\n",
            "          conv64-140             [-1, 64, 8, 8]               0\n",
            "          Linear-141                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 853,018\n",
            "Trainable params: 853,018\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 10.31\n",
            "Params size (MB): 3.25\n",
            "Estimated Total Size (MB): 13.58\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DrGBcvfgBDMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MyModel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqBFBxflE52O",
        "outputId": "038aec77-1b5c-4389-a0a8-5e927ab7fb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv2): conv16(\n",
              "    (Fx1): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx2): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx3): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx4): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx5): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx6): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx7): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx8): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx9): Fx2_16(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (conv3): conv32(\n",
              "    (Fx1_1): Sequential(\n",
              "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (Fx1_2): Sequential(\n",
              "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (residual_mapping): optionA()\n",
              "    (Fx2): Fx2_32(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx3): Fx2_32(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx4): Fx2_32(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx5): Fx2_32(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx6): Fx2_32(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx7): Fx2_32(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx8): Fx2_32(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx9): Fx2_32(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (conv4): conv64(\n",
              "    (Fx1_1): Sequential(\n",
              "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (Fx1_2): Sequential(\n",
              "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (residual_mapping): optionA()\n",
              "    (Fx2): Fx2_64(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx3): Fx2_64(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx4): Fx2_64(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx5): Fx2_64(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx6): Fx2_64(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx7): Fx2_64(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx8): Fx2_64(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "    (Fx9): Fx2_64(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (conv2): Sequential(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (residual): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (fclayer): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VSaKPzed_hys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "O5pbqSQwTRBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #get_model when loading model parameters trained w/ multi-gpu\n",
        "def get_model(model_name, checkpoint_path):\n",
        "    print(\"start loading model parameter\")\n",
        "    model = model_name()\n",
        "    state_dict = torch.load(checkpoint_path)\n",
        "\n",
        "    new_state_dict = OrderedDict()\n",
        "\n",
        "    for k, v in state_dict.items():\n",
        "        name = k.replace('module.', '')\n",
        "        new_state_dict[name] = v\n",
        "    model.load_state_dict(new_state_dict)\n",
        "    print(\"model parameter loaded\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "-7GtYWpoTSBx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(n_epochs, train_loader) :\n",
        " \n",
        "    epochs = n_epochs\n",
        "    train_dataloader = train_loader\n",
        "    #get current time -> folder name\n",
        "    train_date = time.strftime(\"%y%m%d_%H%M\", time.localtime(time.time()))\n",
        "    # print(train_date)\n",
        "\n",
        "    #log path for tensorboard\n",
        "    log_path = os.path.join(os.getcwd(),\"logs\",train_date)\n",
        "    print(\"log_path is {}\".format(log_path))\n",
        "\n",
        "    #model path to save '.pth'file\n",
        "    model_path = os.path.join(os.getcwd(),\"models\",train_date)\n",
        "    print(\"model_path is {}\".format(model_path))\n",
        "    if os.path.isdir(model_path) == False:\n",
        "            os.makedirs(model_path)\n",
        "\n",
        "    #writer for tensorboard\n",
        "    writer = SummaryWriter(log_path)\n",
        " \n",
        "    # whether available GPU\n",
        "    # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    #device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
        "    \n",
        "    #define model (처음부터 학습시)\n",
        "    print(\"처음부터 학습\")\n",
        "    model = MyModel()\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "    model.to(device)\n",
        "\n",
        "    ####### 이전 학습한거에 추가적으로 학습시\n",
        "    # print(\"이전에 하던거 부터 학습\")\n",
        "    # model_name = MyModel\n",
        "    # # /content/models/230412_2145/0.pth\n",
        "    # checkpoint_path = './12.pth'  #수정 필요\n",
        "    # model = get_model(model_name,checkpoint_path)\n",
        "    # model.to(device)\n",
        "\n",
        "    #######\n",
        "\n",
        "    #define loss funcion, optimizer, (scheduler)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(),lr=0.1, momentum=0.9,weight_decay=0.0001)\n",
        "    #lr = 0.025, momentum = 0.9, weight_decay = 0.0005(original)\n",
        "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [81,122], gamma = 0.1)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [81,122], gamma = 0.1)\n",
        "    # 0.1 -> 0.01 (32K iterations = 81 epochs) -> 0.001 (48K iterations = 122 epochs)\n",
        "\n",
        "    print(\"start training\")\n",
        "    #Train\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        model.train(True)\n",
        "        len_trainbatch = len(train_dataloader)\n",
        "\n",
        "        i = 0\n",
        "        for inputs, targets in tqdm(train_dataloader):\n",
        "            i = i+1\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "\n",
        "            writer.add_scalar('train/loss', loss.item(), epoch*len_trainbatch+i) #iterations\n",
        "        \n",
        "        scheduler.step()    \n",
        "        print(\"train loss of {}th epoch is {}\".format(epoch,loss.item())) ## 수정 필요\n",
        " \n",
        "        # Save every N(30) epoch\n",
        "        save_epoch = 30\n",
        "        if save_epoch > 0 and epoch % save_epoch == save_epoch-1:\n",
        "            state_dict = model.state_dict()\n",
        "            torch.save(state_dict, os.path.join(model_path, str(epoch+1)+'.pth')) #epoch+1로 바꾸기\n",
        "        \n",
        "    print('Finished Training')\n",
        "\n",
        "    #save model after training\n",
        "    torch.save(model.state_dict(), './model.pth') \n",
        "\n",
        "   "
      ],
      "metadata": {
        "id": "SYyArqTMTVCW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V7lE9mREKDl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "w83K2YacTWA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main() :\n",
        "\n",
        "    random.seed(53)\n",
        "    #train(163, trainloader) #64k iterations = 163 epochs\n",
        "    train(163, trainloader) #64k iterations = 163 epochs\n",
        "\n",
        "   \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "iDTWlmHSTXfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c15add-2f01-454e-c61f-523b09a14f45"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_path is /content/logs/230417_0053\n",
            "model_path is /content/models/230417_0053\n",
            "처음부터 학습\n",
            "start training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:37<00:00, 10.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 0th epoch is 2.030055522918701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 1th epoch is 1.5957404375076294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:37<00:00, 10.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 2th epoch is 1.1459627151489258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 3th epoch is 0.8990737199783325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 4th epoch is 0.8849180936813354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 5th epoch is 0.5908142924308777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 6th epoch is 0.9640769958496094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 7th epoch is 0.5910776853561401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 8th epoch is 0.7850844860076904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 9th epoch is 0.4737507402896881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 10th epoch is 0.5467962026596069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 11th epoch is 0.6672261953353882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 12th epoch is 0.7558947205543518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 13th epoch is 0.47527456283569336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 14th epoch is 0.5281394124031067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:39<00:00,  9.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 15th epoch is 0.28348448872566223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 16th epoch is 0.3247082829475403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 17th epoch is 0.39010632038116455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 18th epoch is 0.4111756682395935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 19th epoch is 0.40375709533691406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 20th epoch is 0.28552761673927307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:39<00:00, 10.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 21th epoch is 0.29108160734176636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:39<00:00, 10.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 22th epoch is 0.3915952444076538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 23th epoch is 0.41185373067855835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 24th epoch is 0.2807082235813141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:39<00:00, 10.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 25th epoch is 0.24417157471179962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 26th epoch is 0.28556522727012634\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 27th epoch is 0.4323420524597168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 28th epoch is 0.2774924635887146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 29th epoch is 0.3074567914009094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 30th epoch is 0.28785640001296997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 31th epoch is 0.29982703924179077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 32th epoch is 0.3055756390094757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 33th epoch is 0.2561272382736206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 34th epoch is 0.34997421503067017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:37<00:00, 10.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 35th epoch is 0.3829968571662903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 36th epoch is 0.25135284662246704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 37th epoch is 0.2361055612564087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 38th epoch is 0.3471788167953491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 39th epoch is 0.2345007359981537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 40th epoch is 0.21665093302726746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 41th epoch is 0.28711000084877014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 42th epoch is 0.14265333116054535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 43th epoch is 0.23265179991722107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 44th epoch is 0.28829625248908997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 45th epoch is 0.16264373064041138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 46th epoch is 0.20407359302043915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 47th epoch is 0.28001827001571655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 48th epoch is 0.2927939295768738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 49th epoch is 0.3890132009983063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 50th epoch is 0.14497217535972595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 51th epoch is 0.24497553706169128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 52th epoch is 0.27573198080062866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 53th epoch is 0.23567283153533936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 54th epoch is 0.20213353633880615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 55th epoch is 0.18982717394828796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 56th epoch is 0.25167983770370483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 57th epoch is 0.23272867500782013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 58th epoch is 0.11121697723865509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 59th epoch is 0.3144500255584717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 60th epoch is 0.23309239745140076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 61th epoch is 0.21771900355815887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:39<00:00,  9.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 62th epoch is 0.15888497233390808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 63th epoch is 0.18713633716106415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 64th epoch is 0.1998145878314972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 65th epoch is 0.2685139775276184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 66th epoch is 0.18115566670894623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 67th epoch is 0.3548486828804016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 68th epoch is 0.148898184299469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 69th epoch is 0.25491124391555786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 70th epoch is 0.23495957255363464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 71th epoch is 0.24550509452819824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 72th epoch is 0.16642092168331146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 73th epoch is 0.22447487711906433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 74th epoch is 0.20032057166099548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 75th epoch is 0.14449357986450195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 76th epoch is 0.3646814227104187\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 77th epoch is 0.1536167562007904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 78th epoch is 0.18261168897151947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 79th epoch is 0.09992075711488724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 80th epoch is 0.3943110704421997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 81th epoch is 0.09262105822563171\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 82th epoch is 0.19892096519470215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 83th epoch is 0.04646584764122963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 84th epoch is 0.08054593205451965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 85th epoch is 0.03913252800703049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 86th epoch is 0.06747995316982269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 87th epoch is 0.034397948533296585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 88th epoch is 0.05153390020132065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 89th epoch is 0.06402061134576797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 90th epoch is 0.035051118582487106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 91th epoch is 0.06209911033511162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 92th epoch is 0.09059469401836395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 93th epoch is 0.017784034833312035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 94th epoch is 0.027462180703878403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 95th epoch is 0.02615773119032383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 96th epoch is 0.02271723374724388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 97th epoch is 0.017895257100462914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 98th epoch is 0.009932123124599457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 99th epoch is 0.018337052315473557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 100th epoch is 0.007347973994910717\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 101th epoch is 0.013377875089645386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 102th epoch is 0.03766581788659096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 103th epoch is 0.04017730802297592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 104th epoch is 0.022167574614286423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 105th epoch is 0.022118795663118362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 106th epoch is 0.00732098612934351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 107th epoch is 0.036255400627851486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 108th epoch is 0.009732259437441826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 109th epoch is 0.018545683473348618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 110th epoch is 0.0278086569160223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 111th epoch is 0.002464374527335167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 112th epoch is 0.0069209253415465355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 113th epoch is 0.0048287371173501015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 114th epoch is 0.022971123456954956\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 115th epoch is 0.0344507060945034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 116th epoch is 0.004921280778944492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 117th epoch is 0.013057622127234936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 118th epoch is 0.0033934537786990404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:39<00:00,  9.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 119th epoch is 0.022056974470615387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 120th epoch is 0.002788637299090624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 121th epoch is 0.023099152371287346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 122th epoch is 0.004274086561053991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 123th epoch is 0.002205303404480219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 124th epoch is 0.005525748245418072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 125th epoch is 0.023769069463014603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 126th epoch is 0.026958713307976723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 127th epoch is 0.015116879716515541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 128th epoch is 0.010423840954899788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 129th epoch is 0.0006666887202300131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 130th epoch is 0.002875549253076315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 131th epoch is 0.0017277036095038056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 132th epoch is 0.017254739999771118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 133th epoch is 0.01914326101541519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 134th epoch is 0.009331694804131985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 135th epoch is 0.007851017639040947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 136th epoch is 0.035486236214637756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 137th epoch is 0.004480930045247078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 138th epoch is 0.008675245568156242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 139th epoch is 0.01963110640645027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 140th epoch is 0.005661597475409508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 141th epoch is 0.000651311594992876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 142th epoch is 0.0011121530551463366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 143th epoch is 0.0037680231034755707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 144th epoch is 0.012841668911278248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 145th epoch is 0.01655254140496254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 146th epoch is 0.00837524700909853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 147th epoch is 0.0033521712757647038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 148th epoch is 0.002184749348089099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 149th epoch is 0.01188563834875822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 150th epoch is 0.011057361960411072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 151th epoch is 0.003649247344583273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 152th epoch is 0.004863426089286804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 153th epoch is 0.01448771357536316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 154th epoch is 0.010781217366456985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:39<00:00,  9.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 155th epoch is 0.015832137316465378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 156th epoch is 0.00821151863783598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 157th epoch is 0.01233386155217886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 158th epoch is 0.007265823893249035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 159th epoch is 0.0040213423781096935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 160th epoch is 0.006305375602096319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 161th epoch is 0.002765841316431761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:38<00:00, 10.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train loss of 162th epoch is 0.017061877995729446\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n",
        "\n",
        "- model\n",
        "\n",
        "100 100 Loss: 0.344 | Acc: 92.530% (9253/10000)\n",
        "\n",
        "\n",
        "- 30\n",
        "\n",
        "100 Loss: 0.549 | Acc: 82.450% (8245/10000)\n",
        "\n",
        "\n",
        "- 60\n",
        "\n",
        "100 100 Loss: 0.475 | Acc: 85.630% (8563/10000)\n",
        "\n",
        "- 90\n",
        "\n",
        "100 100 Loss: 0.285 | Acc: 92.240% (9224/10000)\n",
        "\n",
        "\n",
        "- 120\n",
        "\n",
        "100 100 Loss: 0.343 | Acc: 92.430% (9243/10000)\n",
        "\n",
        "- 150\n",
        "\n",
        "100 100 Loss: 0.341 | Acc: 92.460% (9246/10000)"
      ],
      "metadata": {
        "id": "yee8xUPgTaDl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kIUXbglZvAIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "\n",
        "    ####### not touch\n",
        "    model_name = MyModel\n",
        "    # /content/models/230412_2145/0.pth\n",
        "    #/content/models/230412_2208/1.pth\n",
        "    #/content/models/230416_0841/90.pth\n",
        "    #/content/models/230417_0053/30.pth\n",
        "    checkpoint_path = './models/230417_0053/150.pth'  #수정 필요\n",
        "    mode = 'test' \n",
        "#     data_dir = \"./test_data\"\n",
        "#     meta_path = \"./answer.json\"\n",
        "    model = get_model(model_name,checkpoint_path)\n",
        "    #######\n",
        "    \n",
        "#     # Create training and validation datasets\n",
        "#     test_datasets = MyDataset(meta_path, data_dir, data_transforms['test'],is_train= False) #self,meta_path,root_dir,transform=None, is_train = True\n",
        "\n",
        "#     # Create training and validation dataloaders\n",
        "#     test_dataloader = torch.utils.data.DataLoader(test_datasets, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    test_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=data_transforms['test'])\n",
        "    \n",
        "    testloader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=100, shuffle=False, num_workers=2)\n",
        "    \n",
        "    # Detect if we have a GPU available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # device = torch.device(\"mps\") if torch.backends.mps.is_available() else \"cpu\"\n",
        "    \n",
        "    # Send the model to GPU\n",
        "    #multi-GPU\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        model = nn.DataParallel(model)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Set model as evaluation mode\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    model.eval()\n",
        "    \n",
        "    # Inference\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        batch_idx = 0\n",
        "        for inputs, targets in tqdm(testloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            \n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            batch_idx = batch_idx + 1\n",
        "            print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n"
      ],
      "metadata": {
        "id": "tKTiQf_m2CYa"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main() :\n",
        "\n",
        "    random.seed(53)\n",
        "    test()\n",
        "\n",
        "   \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sclg27K2DVj",
        "outputId": "b2f8f238-7f83-438c-9a85-72c5afba0fa4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start loading model parameter\n",
            "model parameter loaded\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 2/100 [00:00<00:17,  5.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 100 Loss: 0.119 | Acc: 95.000% (95/100)\n",
            "2 100 Loss: 0.205 | Acc: 93.500% (187/200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 6/100 [00:00<00:07, 12.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 100 Loss: 0.181 | Acc: 94.667% (284/300)\n",
            "4 100 Loss: 0.230 | Acc: 93.750% (375/400)\n",
            "5 100 Loss: 0.257 | Acc: 93.800% (469/500)\n",
            "6 100 Loss: 0.247 | Acc: 94.167% (565/600)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 11/100 [00:00<00:04, 18.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 100 Loss: 0.267 | Acc: 93.857% (657/700)\n",
            "8 100 Loss: 0.283 | Acc: 93.375% (747/800)\n",
            "9 100 Loss: 0.301 | Acc: 93.222% (839/900)\n",
            "10 100 Loss: 0.312 | Acc: 93.100% (931/1000)\n",
            "11 100 Loss: 0.301 | Acc: 93.273% (1026/1100)\n",
            "12"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 17/100 [00:01<00:03, 22.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100 Loss: 0.304 | Acc: 93.167% (1118/1200)\n",
            "13 100 Loss: 0.307 | Acc: 93.000% (1209/1300)\n",
            "14 100 Loss: 0.306 | Acc: 93.000% (1302/1400)\n",
            "15 100 Loss: 0.303 | Acc: 93.000% (1395/1500)\n",
            "16 100 Loss: 0.296 | Acc: 93.125% (1490/1600)\n",
            "17 100 Loss: 0.303 | Acc: 93.176% (1584/1700)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 23/100 [00:01<00:03, 24.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18 100 Loss: 0.309 | Acc: 92.889% (1672/1800)\n",
            "19 100 Loss: 0.315 | Acc: 92.684% (1761/1900)\n",
            "20 100 Loss: 0.335 | Acc: 92.600% (1852/2000)\n",
            "21 100 Loss: 0.340 | Acc: 92.476% (1942/2100)\n",
            "22 100 Loss: 0.346 | Acc: 92.227% (2029/2200)\n",
            "23 100 Loss: 0.346 | Acc: 92.174% (2120/2300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 29/100 [00:01<00:02, 25.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24 100 Loss: 0.351 | Acc: 92.083% (2210/2400)\n",
            "25 100 Loss: 0.358 | Acc: 92.000% (2300/2500)\n",
            "26 100 Loss: 0.371 | Acc: 91.769% (2386/2600)\n",
            "27 100 Loss: 0.364 | Acc: 91.852% (2480/2700)\n",
            "28 100 Loss: 0.364 | Acc: 91.929% (2574/2800)\n",
            "29 100 Loss: 0.363 | Acc: 91.966% (2667/2900)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 35/100 [00:01<00:02, 26.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 100 Loss: 0.361 | Acc: 91.967% (2759/3000)\n",
            "31 100 Loss: 0.356 | Acc: 91.968% (2851/3100)\n",
            "32 100 Loss: 0.353 | Acc: 92.031% (2945/3200)\n",
            "33 100 Loss: 0.353 | Acc: 92.061% (3038/3300)\n",
            "34 100 Loss: 0.349 | Acc: 92.176% (3134/3400)\n",
            "35 100 Loss: 0.351 | Acc: 92.114% (3224/3500)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:01<00:02, 27.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 100 Loss: 0.352 | Acc: 92.111% (3316/3600)\n",
            "37 100 Loss: 0.359 | Acc: 92.000% (3404/3700)\n",
            "38 100 Loss: 0.363 | Acc: 91.921% (3493/3800)\n",
            "39 100 Loss: 0.360 | Acc: 92.026% (3589/3900)\n",
            "40 100 Loss: 0.361 | Acc: 92.025% (3681/4000)\n",
            "41 100 Loss: 0.366 | Acc: 91.951% (3770/4100)\n",
            "42 100 Loss: 0.366 | Acc: 91.976% (3863/4200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 46/100 [00:02<00:01, 28.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43 100 Loss: 0.362 | Acc: 92.070% (3959/4300)\n",
            "44 100 Loss: 0.362 | Acc: 92.159% (4055/4400)\n",
            "45 100 Loss: 0.359 | Acc: 92.200% (4149/4500)\n",
            "46 100 Loss: 0.362 | Acc: 92.109% (4237/4600)\n",
            "47 100 Loss: 0.361 | Acc: 92.128% (4330/4700)\n",
            "48 100 Loss: 0.366 | Acc: 92.000% (4416/4800)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 52/100 [00:02<00:01, 26.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49 100 Loss: 0.360 | Acc: 92.082% (4512/4900)\n",
            "50 100 Loss: 0.363 | Acc: 92.060% (4603/5000)\n",
            "51 100 Loss: 0.359 | Acc: 92.137% (4699/5100)\n",
            "52 100 Loss: 0.359 | Acc: 92.173% (4793/5200)\n",
            "53 100 Loss: 0.356 | Acc: 92.226% (4888/5300)\n",
            "54 100 Loss: 0.355 | Acc: 92.241% (4981/5400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 59/100 [00:02<00:01, 27.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55 100 Loss: 0.358 | Acc: 92.218% (5072/5500)\n",
            "56 100 Loss: 0.357 | Acc: 92.268% (5167/5600)\n",
            "57 100 Loss: 0.358 | Acc: 92.228% (5257/5700)\n",
            "58 100 Loss: 0.353 | Acc: 92.293% (5353/5800)\n",
            "59 100 Loss: 0.356 | Acc: 92.237% (5442/5900)\n",
            "60 100 Loss: 0.355 | Acc: 92.217% (5533/6000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 66/100 [00:02<00:01, 27.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "61 100 Loss: 0.355 | Acc: 92.213% (5625/6100)\n",
            "62 100 Loss: 0.353 | Acc: 92.242% (5719/6200)\n",
            "63 100 Loss: 0.351 | Acc: 92.270% (5813/6300)\n",
            "64 100 Loss: 0.348 | Acc: 92.312% (5908/6400)\n",
            "65 100 Loss: 0.345 | Acc: 92.323% (6001/6500)\n",
            "66 100 Loss: 0.342 | Acc: 92.379% (6097/6600)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 72/100 [00:03<00:01, 26.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67 100 Loss: 0.340 | Acc: 92.388% (6190/6700)\n",
            "68 100 Loss: 0.343 | Acc: 92.368% (6281/6800)\n",
            "69 100 Loss: 0.343 | Acc: 92.362% (6373/6900)\n",
            "70 100 Loss: 0.343 | Acc: 92.343% (6464/7000)\n",
            "71 100 Loss: 0.344 | Acc: 92.338% (6556/7100)\n",
            "72 100 Loss: 0.343 | Acc: 92.347% (6649/7200)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 78/100 [00:03<00:00, 27.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73 100 Loss: 0.342 | Acc: 92.342% (6741/7300)\n",
            "74 100 Loss: 0.342 | Acc: 92.365% (6835/7400)\n",
            "75 100 Loss: 0.345 | Acc: 92.373% (6928/7500)\n",
            "76 100 Loss: 0.346 | Acc: 92.368% (7020/7600)\n",
            "77 100 Loss: 0.346 | Acc: 92.390% (7114/7700)\n",
            "78 100 Loss: 0.347 | Acc: 92.397% (7207/7800)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [00:03<00:00, 26.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79 100 Loss: 0.344 | Acc: 92.418% (7301/7900)\n",
            "80 100 Loss: 0.344 | Acc: 92.412% (7393/8000)\n",
            "81 100 Loss: 0.343 | Acc: 92.432% (7487/8100)\n",
            "82 100 Loss: 0.340 | Acc: 92.463% (7582/8200)\n",
            "83 100 Loss: 0.342 | Acc: 92.434% (7672/8300)\n",
            "84 100 Loss: 0.341 | Acc: 92.405% (7762/8400)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 88/100 [00:03<00:00, 27.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85 100 Loss: 0.341 | Acc: 92.376% (7852/8500)\n",
            "86 100 Loss: 0.344 | Acc: 92.349% (7942/8600)\n",
            "87 100 Loss: 0.343 | Acc: 92.356% (8035/8700)\n",
            "88 100 Loss: 0.342 | Acc: 92.398% (8131/8800)\n",
            "89 100 Loss: 0.341 | Acc: 92.382% (8222/8900)\n",
            "90 100 Loss: 0.340 | Acc: 92.422% (8318/9000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 96/100 [00:03<00:00, 28.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91 100 Loss: 0.339 | Acc: 92.451% (8413/9100)\n",
            "92 100 Loss: 0.338 | Acc: 92.467% (8507/9200)\n",
            "93 100 Loss: 0.341 | Acc: 92.398% (8593/9300)\n",
            "94 100 Loss: 0.342 | Acc: 92.372% (8683/9400)\n",
            "95 100 Loss: 0.341 | Acc: 92.389% (8777/9500)\n",
            "96 100 Loss: 0.342 | Acc: 92.375% (8868/9600)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:04<00:00, 24.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "97 100 Loss: 0.340 | Acc: 92.423% (8965/9700)\n",
            "98 100 Loss: 0.340 | Acc: 92.439% (9059/9800)\n",
            "99 100 Loss: 0.340 | Acc: 92.444% (9152/9900)\n",
            "100 100 Loss: 0.341 | Acc: 92.460% (9246/10000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wkCJz2fj68BM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}